{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Bidirectional\n",
    "from keras.layers.recurrent import GRU\n",
    "\n",
    "from encrypt import *\n",
    "from tools import *\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "letters = string.printable.split('!')[0]\n",
    "encrypt = shifted_vigenere_cipher\n",
    "samples_count = 200000\n",
    "text_length = 10\n",
    "\n",
    "set_characters(letters)\n",
    "model_path = f\"models/{encrypt.__name__}_{len(letters)}x{text_length}_best_model.h5\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating and Preparing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = generate_text(text_length, samples_count)\n",
    "cipher = list(map(encrypt, text))\n",
    "\n",
    "train_text = to_vec(text)\n",
    "train_cipher = to_vec(cipher)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building and Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bidirectional_1 (Bidirection (None, 10, 128)           25344     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10, 1)             129       \n",
      "=================================================================\n",
      "Total params: 25,473\n",
      "Trainable params: 25,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Bidirectional(GRU(64, activation='relu', return_sequences=True), input_shape=train_cipher.shape[1:]))\n",
    "model.add(Dense(1))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 180000 samples, validate on 20000 samples\n",
      "Epoch 1/10\n",
      "180000/180000 [==============================] - 115s 640us/step - loss: 27.1789 - acc: 0.2557 - val_loss: 1.3223 - val_acc: 0.4839\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.48393, saving model to models/shifted_vigenere_cipher_62x10_best_model.h5\n",
      "Epoch 2/10\n",
      "180000/180000 [==============================] - 116s 645us/step - loss: 2.3870 - acc: 0.5080 - val_loss: 1.0974 - val_acc: 0.5592\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.48393 to 0.55923, saving model to models/shifted_vigenere_cipher_62x10_best_model.h5\n",
      "Epoch 3/10\n",
      "180000/180000 [==============================] - 117s 651us/step - loss: 1.3536 - acc: 0.6661 - val_loss: 0.2097 - val_acc: 0.7917\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.55923 to 0.79167, saving model to models/shifted_vigenere_cipher_62x10_best_model.h5\n",
      "Epoch 4/10\n",
      "180000/180000 [==============================] - 117s 653us/step - loss: 0.8169 - acc: 0.7692 - val_loss: 0.1487 - val_acc: 0.8755\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.79167 to 0.87551, saving model to models/shifted_vigenere_cipher_62x10_best_model.h5\n",
      "Epoch 5/10\n",
      "180000/180000 [==============================] - 118s 657us/step - loss: 0.7576 - acc: 0.8042 - val_loss: 0.0938 - val_acc: 0.9095\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.87551 to 0.90954, saving model to models/shifted_vigenere_cipher_62x10_best_model.h5\n",
      "Epoch 6/10\n",
      "180000/180000 [==============================] - 119s 660us/step - loss: 0.6213 - acc: 0.8360 - val_loss: 0.2336 - val_acc: 0.8351\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.90954\n",
      "Epoch 7/10\n",
      "180000/180000 [==============================] - 120s 667us/step - loss: 0.5072 - acc: 0.8599 - val_loss: 0.0972 - val_acc: 0.9194\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.90954 to 0.91945, saving model to models/shifted_vigenere_cipher_62x10_best_model.h5\n",
      "Epoch 8/10\n",
      "180000/180000 [==============================] - 120s 665us/step - loss: 0.3810 - acc: 0.8962 - val_loss: 0.0804 - val_acc: 0.9447\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.91945 to 0.94473, saving model to models/shifted_vigenere_cipher_62x10_best_model.h5\n",
      "Epoch 9/10\n",
      "180000/180000 [==============================] - 121s 671us/step - loss: 0.4691 - acc: 0.8873 - val_loss: 0.0485 - val_acc: 0.9745\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.94473 to 0.97446, saving model to models/shifted_vigenere_cipher_62x10_best_model.h5\n",
      "Epoch 10/10\n",
      "180000/180000 [==============================] - 121s 671us/step - loss: 0.4985 - acc: 0.8856 - val_loss: 0.0689 - val_acc: 0.9457\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.97446\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x184f22db320>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=3, verbose=1, mode='min'),\n",
    "    ModelCheckpoint(model_path, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "]\n",
    "model.compile(loss='mse', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(train_cipher, train_text, validation_split=.1, batch_size=10, epochs=10, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting and Evaluating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model predicted that original text is: HelloWorld\n",
      "Test cipher vs encrypted prediction: 2vzunIgopt vs 2vzunIgopt\n"
     ]
    }
   ],
   "source": [
    "test_cyhper = encrypt('HelloWorld')\n",
    "prediction = to_txt(model.predict(to_vec(test_cyhper)))\n",
    "\n",
    "print('Model predicted that original text is:', prediction)\n",
    "print('Test cipher vs encrypted prediction:', test_cyhper, 'vs', encrypt(prediction))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
